{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "matrices: $A x B = C (n*m \\cross m*k = n*k)$\n",
    "$rang(C) \\leq m$\n",
    "$y=Ax \\implies z=By ?\\implies ?z=Cx$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Задача регрессии (e.g. МНК)\n",
    "$y = \\sigma (Ax) = f(A,x)$\n",
    "Задача принадлежности к разным классам - получаем ответ в виде вероятностей\n",
    "$p=f(x,\\theta)$\n",
    "$\\sum_k p_k=1, p_k\\geq 0$\n",
    "softmax: $R^n\\to$вероятность распределения\n",
    "$softmax (x)_k= \\dfrac{e^{x_k}}{\\sum_k e^{x_k}}$\n",
    "$argmax (x)_k = 1, x_k\\geq x_j,\\forall j$\n",
    "$\\implies p = softmax(Ax+b)$\n",
    "Задача предсказания\n",
    "Например, временных рядов:\n",
    "$x_k, x_{k+1}, x_{k+2}, ...$\n",
    "$x_{k+1} = f(x_k, x_{k-1}, x_{k-2}, ..., \\theta)$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "кросс-энтропия должна давать ответ, насколько полученное моделью распределение отличается от реального\n",
    "$L=H_{x\\sim\\hat{p_x}}[\\hat{p_x}, softmax(Ax+b)]=\\dfrac{-1}{\\rho}\\sum^{\\bar{S}}_{s=1} \\log \\big(softmax(Ax^s+b)\\big)_{k^s}$\n",
    "средне-квадратическое отклонение\n",
    "$L=\\sum_s (softmax - p_{true})^2$\n",
    "\n",
    "Кросс-энтропия сходится лучше, потому что он чувствительнее к ошибкам модели, которая выдает ненулевые (неединичные) результаты, там где они должны быть"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Пример принадлежности к классу \"крестики\" или \"нолики\" (вероятность крестика - q, нолика - 1-q)\n",
    "$q=a\\cdot x1 + b\\cdot x2 + c$\n",
    "софтмакс будет похож на сигмоиду\n",
    "$\\dfrac{1}{1+e^{-x}}$\n",
    "Через перекрестную энтропию будем варьировать параметры (вращение разделяющей плоскости - a,b , масштаб по оси х - x1,x2, сдвиг - c)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "SVM - метод с другой целевой функцией\n",
    "Support vector machine - изначально определен для бинарной классификации\n",
    "Loss = -distance + lambda*regularization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Рассмотрим задачу: крестики \"кругом\" в окрестности из ноликов. Классические методы не разделят\n",
    "Введем метод, который будет учитывать расстояния между классами:\n",
    "$z= (x_1-x_1^*)^2+(x_2-x_2^*)^2 = x_1^2 +x_2^2 + 2x_1+2x_2 + c$\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Задача предсказания\n",
    "$x_k = \\sin \\omega k\\implies x_{k_1}=ax_k + bx_{k+1}$\n",
    "$x_{k+1} = f(x_k, x_{k-1}, \\theta)$\n",
    "$x_0, x_1 \\to x_1, x_2 \\to x_2, x_3 \\to ... \\to x_k, x_{k+1}$\n",
    "$L = \\sum_k (x_k - x^*_k)^2$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Autoencoder\n",
    "$x\\to [A*]\\to y \\to [B] z$\n",
    "$L = ||x-z||$\n",
    "A* - encoder, B - decoder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
